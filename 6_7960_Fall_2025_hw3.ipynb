{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YIFANK/6.7960/blob/main/6_7960_Fall_2025_hw3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "47cd59de"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from typing import Tuple, Union, Optional, List\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "torch.manual_seed(42)\n",
        "random.seed(42)\n",
        "np.random.seed(42)"
      ],
      "id": "47cd59de"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "baab5229"
      },
      "outputs": [],
      "source": [
        "\n",
        "# a utility for calculating running average\n",
        "class AverageMeter():\n",
        "    def __init__(self):\n",
        "        self.num = 0\n",
        "        self.tot = 0\n",
        "\n",
        "    def update(self, val: float, sz: float):\n",
        "        self.num += val*sz\n",
        "        self.tot += sz\n",
        "\n",
        "    def calculate(self) -> float:\n",
        "        return self.num/self.tot"
      ],
      "id": "baab5229"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3096185a"
      },
      "source": [
        "# Problem 1: Dialogue GPT"
      ],
      "id": "3096185a"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqR5H5044Xvr",
        "outputId": "47e6c056-782f-4b4c-b74a-63579090ce7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=0cd24b8e39245bdf10141422581c69725577ce0a826a2e1a7502b678fb27b3e4\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/46/3b/e29ffbe4ebe614ff224bad40fc6a5773a67a163251585a13a9\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install wget"
      ],
      "id": "lqR5H5044Xvr"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "13a6fe8d"
      },
      "outputs": [],
      "source": [
        "import wget\n",
        "import os\n",
        "if not os.path.exists(\"input.txt\"):\n",
        "    wget.download(\"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\")"
      ],
      "id": "13a6fe8d"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8c9133dc"
      },
      "outputs": [],
      "source": [
        "with open('input.txt', 'r') as f:\n",
        "    raw_text = f.read()\n",
        "all_dialogues = raw_text.split('\\n\\n')\n"
      ],
      "id": "8c9133dc"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e2d6861",
        "outputId": "43ed419a-cdc2-4caf-c18c-04d33031ea4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download(\"punkt_tab\")"
      ],
      "id": "8e2d6861"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccb804ff"
      },
      "source": [
        "## Part 1.A"
      ],
      "id": "ccb804ff"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "20f26a57"
      },
      "outputs": [],
      "source": [
        "def tokenize(s):\n",
        "  return word_tokenize(s)\n",
        "\n",
        "class MyTokenizer:\n",
        "    def __init__(self, raw_text: str):\n",
        "        # raw_text     contains the text from which we will build our vocabulary\n",
        "\n",
        "        self.start = '<START>' # token that starts every example\n",
        "        self.pad = '<PAD>' # token used to pad examples to the same length\n",
        "        self.unk = '<UNK>' # token used if encountering a word not in our vocabulary\n",
        "\n",
        "        vocab = np.unique(tokenize(raw_text))\n",
        "        vocab = np.concatenate([np.array([self.start, self.pad, self.unk]), vocab])\n",
        "\n",
        "        self.vocab = vocab # array of tokens in order\n",
        "        self.tok_to_id = {w: i for i, w in enumerate(vocab)} # mapping of token to ID\n",
        "        self.vocab_size = len(self.vocab) # size of vocabulary\n",
        "\n",
        "    def encode(self, s: str) -> torch.Tensor:\n",
        "        # s           input string\n",
        "        #\n",
        "        # Output\n",
        "        # id_tensor   a tensor of token ids, starting with the start token.t\n",
        "\n",
        "        id_tensor = None\n",
        "\n",
        "        # TODO: tokenize the input using word_tokenize. Return a tensor\n",
        "        # of the token ids, starting with the token id for the start token.\n",
        "        # ============ ANSWER START ===========\n",
        "        words = tokenize(s)\n",
        "        id_list = []\n",
        "        for w in words:\n",
        "          if w not in self.tok_to_id:\n",
        "            id_list.append(self.unk)\n",
        "          else:\n",
        "            id_list.append(w)\n",
        "        id_tensor = torch.tensor([self.tok_to_id[w] for w in id_list],dtype = torch.long)\n",
        "        id_tensor = torch.cat([torch.tensor([self.tok_to_id[self.start]]), id_tensor])\n",
        "        # ============ ANSWER END =============\n",
        "\n",
        "        return id_tensor\n",
        "\n",
        "    def decode(self, toks: torch.Tensor) -> str:\n",
        "        # toks         a list of token ids\n",
        "        #\n",
        "        # Output\n",
        "        # decoded_str  the token ids decoded back into a string (join with a space)\n",
        "\n",
        "        decoded_str = None\n",
        "\n",
        "        # TODO: convert the token ids back to the actual corresponding words.\n",
        "        # Join the tokens with a space and return the full string\n",
        "        # ============ ANSWER START ===========\n",
        "        decoded_str = ' '.join([self.vocab[t] for t in toks])\n",
        "        # ============ ANSWER END =============\n",
        "\n",
        "        return decoded_str\n",
        "\n",
        "    def pad_examples(self, tok_list: List[torch.Tensor]) -> torch.Tensor:\n",
        "        # Pads the tensors to the right with the pad token so that they are the same length.\n",
        "        #\n",
        "        # tok_list       a list of tensors containing token ids (maybe of different lengths)\n",
        "        #\n",
        "        # Output\n",
        "        # padded_tokens  shape: (len(tok_list), max length within tok_list)\n",
        "        return torch.nn.utils.rnn.pad_sequence(tok_list, batch_first=True, padding_value=self.tok_to_id[self.pad])\n",
        "\n",
        "tok = MyTokenizer(raw_text)"
      ],
      "id": "20f26a57"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "328863ef",
        "outputId": "ea13b02f-b2ff-44a1-c3fc-a1e7301a27d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([    0,  1593,  2182,  1481,   223,  2343, 12742,  1476,  5704,  3319,\n",
            "        12795,  6848,  8727,  9608,  7655,   221])\n",
            "<START> KING RICHARD III : Say that I did all this for love of her .\n"
          ]
        }
      ],
      "source": [
        "# tokenizer test cases\n",
        "input_string = 'KING RICHARD III:\\nSay that I did all this for love of her.'\n",
        "enc = tok.encode(input_string)\n",
        "print(enc)\n",
        "dec = tok.decode(enc)\n",
        "print(dec)\n",
        "assert dec == \"<START> KING RICHARD III : Say that I did all this for love of her .\""
      ],
      "id": "328863ef"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3359721d"
      },
      "source": [
        "## Part 1.B"
      ],
      "id": "3359721d"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "60f07f0a"
      },
      "outputs": [],
      "source": [
        "class DialogueDataset:\n",
        "    def __init__(self, tokenizer: MyTokenizer, lines: List[str], max_N: int):\n",
        "        # tokenizer    an instance of MyTokenizer\n",
        "        # lines        a list of strings. each element in an example in the dataset\n",
        "        # max_N        the maximum number of tokens allowed per example. More than this will be truncated\n",
        "        self.lines = lines\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_N = max_N\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.lines)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> torch.Tensor:\n",
        "        # returns the example at int encoded by the tokenizer\n",
        "        # truncates the example if it is more than max_N tokens\n",
        "        return self.tokenizer.encode(self.lines[idx])[:self.max_N]\n",
        "\n",
        "def collate_fn(examples: List[torch.Tensor]):\n",
        "    # examples        a batch of tensors containing token ids (maybe of different lengths)\n",
        "    # Outputs a dictionary containing\n",
        "    #   input_ids     a single tensor with all of the examples padded (from the right) to the max\n",
        "    #                 length within the batch. shape:(B, max length within examples)\n",
        "    #   input_mask    a tensor indicating which tokens are padding and should be ignored. 0 if padding\n",
        "    #                 and 1 if not. shape: (B, max length within examples)\n",
        "    new_input_ids = tok.pad_examples(examples)\n",
        "    attn_mask = torch.ones(new_input_ids.shape)\n",
        "    attn_mask[new_input_ids == tok.tok_to_id[tok.pad]] = 0\n",
        "    return {'input_ids': tok.pad_examples(examples), 'input_mask': attn_mask}\n",
        "\n",
        "ds = DialogueDataset(tok, all_dialogues, max_N=200)\n",
        "training_dl = torch.utils.data.DataLoader(ds, batch_size=64, collate_fn=collate_fn)"
      ],
      "id": "60f07f0a"
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "930c4fde",
        "outputId": "387d6009-d7b0-4ba9-b1e2-b4724d6d3b46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[   0, 1151,  708,  ...,    1,    1,    1],\n",
            "        [   0,  323,  223,  ...,    1,    1,    1],\n",
            "        [   0, 1151,  708,  ...,    1,    1,    1],\n",
            "        ...,\n",
            "        [   0, 1733,  223,  ...,    1,    1,    1],\n",
            "        [   0, 1151, 2385,  ...,    1,    1,    1],\n",
            "        [   0, 1733,  223,  ...,    1,    1,    1]]), 'input_mask': tensor([[1., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [1., 1., 1.,  ..., 0., 0., 0.]])}\n"
          ]
        }
      ],
      "source": [
        "# take a look at an example of an element from the training dataloader\n",
        "for batch in training_dl:\n",
        "    print(batch)\n",
        "    break"
      ],
      "id": "930c4fde"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f980fc7d"
      },
      "source": [
        "## Part 1.C"
      ],
      "id": "f980fc7d"
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "f37a893a"
      },
      "outputs": [],
      "source": [
        "class DialogueGPT(nn.Module):\n",
        "    def __init__(self, vocab_size: int, max_N: int, dim: int, mlp_dim: int, num_heads: int, num_layers: int):\n",
        "        # vocab_size       size of the vocabulary\n",
        "        # max_N            maximum number of tokens allowed to appear in 1 example\n",
        "        # dim              embedding dimension\n",
        "        # mlp_dim          the hidden layer dimension of the FFN\n",
        "        # num_heads        the number of heads in the attention layer\n",
        "        # num_layers       the number of attention layers.\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # TODO: set up the token embedding and positional embeddings\n",
        "        #       Hint, use nn.Embedding\n",
        "        # ============ ANSWER START ============\n",
        "        self.token_emb = nn.Embedding(vocab_size, dim)\n",
        "        self.pos_emb = nn.Embedding(max_N, dim)\n",
        "        # ============ ANSWER END ==============\n",
        "\n",
        "        # NOTE: Even though we use a TransformerEncoder, applying a causal attention mask makes it behavior like a GPT-style decoder.\n",
        "        transformer_layer = nn.TransformerEncoderLayer(d_model=dim, nhead=num_heads, dim_feedforward=mlp_dim, batch_first=True)\n",
        "        self.transformer = nn.TransformerEncoder(transformer_layer, num_layers=num_layers)\n",
        "\n",
        "\n",
        "        self.head = nn.Sequential(\n",
        "            nn.LayerNorm(dim),\n",
        "            nn.Linear(dim, vocab_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids: torch.Tensor) -> Tuple[torch.Tensor, Optional[torch.Tensor]]:\n",
        "        # input_ids     a batch of input ids (right padded). shape: (B x T)\n",
        "        #\n",
        "        # Output\n",
        "        # out           the logit vector (B x T x V)\n",
        "        # alphas        the attention weights if return_attn is True. Otherwise None shape: (B, num_layers, num_heads, T, T)\n",
        "\n",
        "        embs = None\n",
        "\n",
        "        # TODO: retrieve the token embeddings for the input_ids.\n",
        "        #       Add to the token embeddings the positional embeddings.\n",
        "        #       Store the combined embedding in embs\n",
        "        # ============ ANSWER START ============\n",
        "        device = input_ids.device\n",
        "        B, T = input_ids.shape\n",
        "        pos_ids = torch.arange(T, device=device)\n",
        "        embs = self.token_emb(input_ids) + self.pos_emb(pos_ids)\n",
        "        # ============ ANSWER END ============\n",
        "\n",
        "        causal_attn_mask = None\n",
        "\n",
        "        # TODO: Create the causal attention mask, which should be a boolean tensor of size (T, T).\n",
        "        #       Remember that the causal attention mask is lower triangular (all tokens only\n",
        "        #       depend on themselves and the tokens before them).\n",
        "        #       In PyTorch's TransformerEncoder, True indicates positions to ignore, so you need to invert the mask.\n",
        "        #       Store the mask in causal_attn_mask\n",
        "        # Hint: check out torch.tril\n",
        "        # ============ ANSWER START ============\n",
        "        causal_attn_mask = torch.tril(torch.ones(input_ids.shape[1], input_ids.shape[1])).bool()\n",
        "        causal_attn_mask = causal_attn_mask.to(device)\n",
        "        # ============ ANSWER END ==============\n",
        "\n",
        "        x = self.transformer(embs, mask=causal_attn_mask)\n",
        "        out = self.head(x)\n",
        "        return out\n",
        "\n",
        "    def generate(self, input_ids, num_tokens):\n",
        "        # you can assume batch size 1\n",
        "        with torch.no_grad():\n",
        "            for i in range(num_tokens):\n",
        "                out = self.forward(input_ids)\n",
        "                new_token = torch.argmax(out[:, [-1]], -1)\n",
        "                input_ids = torch.cat([input_ids, new_token], dim=1)\n",
        "        return input_ids"
      ],
      "id": "f37a893a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8b5f097"
      },
      "source": [
        "## Part 1.D"
      ],
      "id": "a8b5f097"
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "a91f3300"
      },
      "outputs": [],
      "source": [
        "\n",
        "class DialogueLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "\n",
        "    def forward(self, logits: torch.Tensor, input_ids: torch.Tensor, inp_mask: torch.Tensor):\n",
        "        # logits      the logits produced by DialogueGPT. shape: (B x T x V)\n",
        "        # input_ids   the token ids. shape: (B x T)\n",
        "        # inp_mask    a 0/1 mask of which tokens are padding tokens and should be ignored. shape: (B x T)\n",
        "\n",
        "        # TODO: Implement the language model loss. For logits[i], we want to supervise the i+1 token_id\n",
        "        # with the cross entropy loss. We thus will not supervise the start token (input_ids[0]) or use\n",
        "        # the last logit vector (logits[-1]). Return the average of the losses for each token in the batch,\n",
        "        # making sure to ignore tokens corresponding to the padding (use inp_mask).\n",
        "\n",
        "        # ============ ANSWER START ============\n",
        "        shift_logits = logits[:, :-1].contiguous()\n",
        "        shift_labels = input_ids[:, 1:].contiguous()\n",
        "        shift_mask = inp_mask[:, 1:].contiguous()\n",
        "        loss = self.criterion(shift_logits.view(-1, shift_logits.shape[-1]), shift_labels.view(-1))\n",
        "        loss = (loss * shift_mask.view(-1))\n",
        "        loss = loss.sum() / shift_mask.sum()\n",
        "        return loss\n",
        "        # ============ ANSWER END ==============\n"
      ],
      "id": "a91f3300"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fa39592a"
      },
      "source": [
        "## Part 1.F"
      ],
      "id": "fa39592a"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "06e5b68b"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "model = DialogueGPT(vocab_size=tok.vocab_size, max_N=200, dim=128, mlp_dim=128, num_heads=4, num_layers=6).cuda()\n",
        "criterion = DialogueLoss()\n",
        "\n",
        "NUM_EPOCHS = 80\n",
        "\n",
        "\n",
        "\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.0001, weight_decay=0)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS)\n"
      ],
      "id": "06e5b68b"
    },
    {
      "cell_type": "code",
      "source": [
        "# Time estimate: around 30 minutes on T4 GPU\n",
        "# Training\n",
        "import tqdm\n",
        "for epoch in range(NUM_EPOCHS):  # loop over the dataset multiple times\n",
        "    loss_meter = AverageMeter()\n",
        "    for inp_dict in tqdm.tqdm(training_dl):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inp_ids, inp_mask = inp_dict['input_ids'], inp_dict['input_mask']\n",
        "        inp_ids = inp_ids.cuda()\n",
        "        inp_mask = inp_mask.cuda()\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(input_ids=inp_ids)\n",
        "        loss = criterion(outputs, inp_ids, inp_mask)\n",
        "        loss_meter.update(loss.item(), len(inp_dict['input_ids']))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    scheduler.step()\n",
        "\n",
        "        # print example\n",
        "    inp = tok.encode(\"\").unsqueeze(0).cuda()\n",
        "    print(tok.decode(model.generate(inp, 10)[0].cpu()))\n",
        "\n",
        "    print(f\"Train Epoch: {epoch}, Loss: {loss_meter.calculate():0.4f}, LR: {scheduler.get_last_lr()[0]}\")\n"
      ],
      "metadata": {
        "id": "zPHuPNQb17uZ",
        "outputId": "b78d8e2c-b5b7-4b7d-d0d6-a80b070d0184",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "zPHuPNQb17uZ",
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.32it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<START> moved , amort your ! PRINCE come , ! !\n",
            "Train Epoch: 0, Loss: 8.6146, LR: 9.996145181203615e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.33it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<START> for : , , , , , . , ,\n",
            "Train Epoch: 1, Loss: 7.2509, LR: 9.98458666866564e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.47it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<START> for : I , , the , : , ,\n",
            "Train Epoch: 2, Loss: 6.6526, LR: 9.965342284774632e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.51it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<START> 'd : I , but , in : to to\n",
            "Train Epoch: 3, Loss: 6.4725, LR: 9.938441702975689e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.51it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<START> KING : I , and , and . , but\n",
            "Train Epoch: 4, Loss: 6.3191, LR: 9.903926402016153e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.44it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<START> KING : I : I the , I : I\n",
            "Train Epoch: 5, Loss: 6.1179, LR: 9.861849601988383e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.44it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<START> KING : What , and , and ? , and\n",
            "Train Epoch: 6, Loss: 5.9279, LR: 9.812276182268236e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.45it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<START> KING : What , and me , and me ,\n",
            "Train Epoch: 7, Loss: 5.7067, LR: 9.755282581475769e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.45it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<START> KING : What , but a the your me ,\n",
            "Train Epoch: 8, Loss: 5.4391, LR: 9.690956679612421e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.46it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<START> KING : What , And , and ? , And\n",
            "Train Epoch: 9, Loss: 5.1460, LR: 9.619397662556433e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.46it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<START> KING : What , sir , but a the ,\n",
            "Train Epoch: 10, Loss: 4.8637, LR: 9.540715869125406e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.45it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<START> First : What , sir , sir more to me\n",
            "Train Epoch: 11, Loss: 4.6051, LR: 9.455032620941839e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.43it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<START> First : What , sir , But 's , But\n",
            "Train Epoch: 12, Loss: 4.3648, LR: 9.362480035363986e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.45it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<START> KING : What , sir , sir my me ,\n",
            "Train Epoch: 13, Loss: 4.1363, LR: 9.263200821770461e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.46it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<START> First : What , That thy , sir , But\n",
            "Train Epoch: 14, Loss: 3.9204, LR: 9.157348061512727e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.46it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<START> KING : What , sir , But he him .\n",
            "Train Epoch: 15, Loss: 3.7161, LR: 9.045084971874738e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.46it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<START> KING : What , sir , But that all !\n",
            "Train Epoch: 16, Loss: 3.5263, LR: 8.926584654403724e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.47it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<START> KING : What , That thy would my heart But\n",
            "Train Epoch: 17, Loss: 3.3481, LR: 8.802029828000156e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.46it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<START> KING : What 'll , But as he had at\n",
            "Train Epoch: 18, Loss: 3.1792, LR: 8.671612547178429e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.46it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<START> KING : What 'll to come as he had are\n",
            "Train Epoch: 19, Loss: 3.0221, LR: 8.535533905932738e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.46it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<START> KING : But must then ? If of mine own\n",
            "Train Epoch: 20, Loss: 2.8781, LR: 8.39400372766471e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.46it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<START> ISABELLA : But must then will , Which thou art\n",
            "Train Epoch: 21, Loss: 2.7420, LR: 8.247240241650919e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.44it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<START> First : If not hath but what have all '\n",
            "Train Epoch: 22, Loss: 2.6195, LR: 8.095469746549169e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.43it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<START> ISABELLA : If not then ? By if me ,\n",
            "Train Epoch: 23, Loss: 2.5014, LR: 7.938926261462365e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.45it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<START> SICINIUS : If this most thou art You all '\n",
            "Train Epoch: 24, Loss: 2.3918, LR: 7.77785116509801e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.46it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<START> TRANIO : Nay , Which thou art You , But\n",
            "Train Epoch: 25, Loss: 2.2909, LR: 7.612492823579744e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.45it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<START> KING : If heart That thy head -- ' again\n",
            "Train Epoch: 26, Loss: 2.1978, LR: 7.443106207484775e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.44it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<START> KING : If not hath but old my heart make\n",
            "Train Epoch: 27, Loss: 2.1110, LR: 7.269952498697733e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.45it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<START> ROMEO : Here eyes as there , Not should make\n",
            "Train Epoch: 28, Loss: 2.0304, LR: 7.093298687687139e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.45it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<START> ISABELLA : If head dear said make my heart We\n",
            "Train Epoch: 29, Loss: 1.9541, LR: 6.913417161825447e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.45it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<START> SICINIUS : If not hath but old my brother come\n",
            "Train Epoch: 30, Loss: 1.8856, LR: 6.730585285387463e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.45it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<START> SICINIUS : If not then ? If As thou art\n",
            "Train Epoch: 31, Loss: 1.8187, LR: 6.545084971874736e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.46it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<START> TRANIO : If Were prince All ? Nay , Yet\n",
            "Train Epoch: 32, Loss: 1.7579, LR: 6.35720224932537e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.45it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<START> ROMEO : If heart My , Which thou mine own\n",
            "Train Epoch: 33, Loss: 1.7012, LR: 6.167226819279526e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.43it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<START> ROMEO : If Were makes thy men my heart We\n",
            "Train Epoch: 34, Loss: 1.6465, LR: 5.97545161008064e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.45it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<START> TRANIO : If little prince All ? You had be\n",
            "Train Epoch: 35, Loss: 1.5978, LR: 5.782172325201153e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.46it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<START> ROMEO : If Were forth believe long To make now\n",
            "Train Epoch: 36, Loss: 1.5511, LR: 5.587686987289187e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.45it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<START> COMINIUS : If Were night made better two IV king\n",
            "Train Epoch: 37, Loss: 1.5077, LR: 5.392295478639223e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.44it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<START> COMINIUS : If Were night she news , Then eyes\n",
            "Train Epoch: 38, Loss: 1.4665, LR: 5.196299078795341e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.44it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<START> COMINIUS : If Were child know Where I pray eyes\n",
            "Train Epoch: 39, Loss: 1.4285, LR: 4.999999999999998e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.45it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<START> COMINIUS : If honour My , Which thou hast again\n",
            "Train Epoch: 40, Loss: 1.3936, LR: 4.8037009212046566e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.45it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<START> SICINIUS Is Why , Which thou art thou hast eyes\n",
            "Train Epoch: 41, Loss: 1.3601, LR: 4.6077045213607746e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.45it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<START> TRANIO : If Were night she oath hast heart We\n",
            "Train Epoch: 42, Loss: 1.3277, LR: 4.4123130127108115e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.45it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<START> TRANIO : If Were night she comes true eyes made\n",
            "Train Epoch: 43, Loss: 1.2995, LR: 4.217827674798846e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.44it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<START> BIONDELLO : If Were night she report themselves old things\n",
            "Train Epoch: 44, Loss: 1.2725, LR: 4.024548389919358e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.44it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<START> BIONDELLO : If Were night she children old bed eyes\n",
            "Train Epoch: 45, Loss: 1.2467, LR: 3.832773180720473e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.44it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<START> TRANIO : If friends comes made born my troth out\n",
            "Train Epoch: 46, Loss: 1.2234, LR: 3.642797750674627e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.45it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<START> COMINIUS : If Were night she report o'er him are\n",
            "Train Epoch: 47, Loss: 1.2017, LR: 3.454915028125263e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.45it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<START> COMINIUS : Away My told do better two IV are\n",
            "Train Epoch: 48, Loss: 1.1808, LR: 3.269414714612536e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.45it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<START> PAULINA : Away fair hate since oath hast heart eyes\n",
            "Train Epoch: 49, Loss: 1.1597, LR: 3.086582838174551e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.44it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<START> COMINIUS : If Were forth believe comes true eyes made\n",
            "Train Epoch: 50, Loss: 1.1418, LR: 2.9067013123128613e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.46it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<START> COMINIUS : If dear thank prince , Not give report\n",
            "Train Epoch: 51, Loss: 1.1269, LR: 2.7300475013022666e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.45it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<START> COMINIUS : Nay , Which she oath hast return eyes\n",
            "Train Epoch: 52, Loss: 1.1102, LR: 2.556893792515225e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.44it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<START> ROMEO : If Were despair grave death As All So\n",
            "Train Epoch: 53, Loss: 1.0948, LR: 2.3875071764202563e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.43it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<START> TRANIO : If Were night left late of night since\n",
            "Train Epoch: 54, Loss: 1.0825, LR: 2.222148834901989e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.45it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<START> TRANIO : If Were forth believe even by had be\n",
            "Train Epoch: 55, Loss: 1.0703, LR: 2.0610737385376352e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<START> COMINIUS : If Were night she oath hast kings Go\n",
            "Train Epoch: 56, Loss: 1.0597, LR: 1.9045302534508318e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<START> TRANIO : If Were night she frown thou hast again\n",
            "Train Epoch: 57, Loss: 1.0481, LR: 1.7527597583490826e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<START> COMINIUS : If Were night she oath hast off purpose\n",
            "Train Epoch: 58, Loss: 1.0391, LR: 1.6059962723352925e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<START> COMINIUS : If Were Tower had prison he had heavens\n",
            "Train Epoch: 59, Loss: 1.0303, LR: 1.4644660940672629e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<START> PAULINA : If Were night she loves from the Tower\n",
            "Train Epoch: 60, Loss: 1.0237, LR: 1.3283874528215718e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<START> ROMEO : If black comes Marcius late of RICHARD III\n",
            "Train Epoch: 61, Loss: 1.0158, LR: 1.1979701719998453e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<START> ROMEO : If Were Tower had crown thee duke All\n",
            "Train Epoch: 62, Loss: 1.0089, LR: 1.0734153455962748e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<START> Pedant : If Were prince All tender only , See\n",
            "Train Epoch: 63, Loss: 1.0030, LR: 9.549150281252633e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<START> COMINIUS : If Were Tower had prison he had since\n",
            "Train Epoch: 64, Loss: 0.9985, LR: 8.426519384872749e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<START> AUFIDIUS : If Were Tower had such you would eyes\n",
            "Train Epoch: 65, Loss: 0.9931, LR: 7.3679917822953905e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<START> COMINIUS : If Were forth believe even in RICHARD II\n",
            "Train Epoch: 66, Loss: 0.9893, LR: 6.375199646360152e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 113/113 [00:15<00:00,  7.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<START> COMINIUS : If died within known men I pray eyes\n",
            "Train Epoch: 67, Loss: 0.9851, LR: 5.44967379058161e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 73%|███████▎  | 82/113 [00:11<00:04,  7.01it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a66ac1b1"
      },
      "source": [
        "## Part 1.G"
      ],
      "id": "a66ac1b1"
    },
    {
      "cell_type": "code",
      "source": [
        "inp = tok.encode(\"\").unsqueeze(0).cuda()\n",
        "print(tok.decode(model.generate(inp, 50)[0].cpu()))"
      ],
      "metadata": {
        "id": "-401s9lBpzqe"
      },
      "id": "-401s9lBpzqe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 2: What's inside a model?"
      ],
      "metadata": {
        "id": "I1_tP_2qOOaS"
      },
      "id": "I1_tP_2qOOaS"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "w1w1Jx4rMIBF"
      },
      "id": "w1w1Jx4rMIBF"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set seed for reproducibility"
      ],
      "metadata": {
        "id": "qoNvDSJTLWgC"
      },
      "id": "qoNvDSJTLWgC"
    },
    {
      "cell_type": "code",
      "source": [
        "import os, random, numpy as np, torch\n",
        "\n",
        "SEED = 7960  # Do not change\n",
        "\n",
        "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":16:8\"\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "# Torch determinism switches\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.backends.cudnn.deterministic = True\n",
        "try:\n",
        "    torch.use_deterministic_algorithms(True, warn_only=True)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "print(\"Determinism set with SEED =\", SEED)\n"
      ],
      "metadata": {
        "id": "0itrkRXfr48R"
      },
      "execution_count": null,
      "outputs": [],
      "id": "0itrkRXfr48R"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model setup (pretrained ResNet-50)\n",
        "\n",
        "We will use a pretrained **ResNet-50** (trained on ImageNet). We’ll also set up ImageNet normalization utilities for feature synthesis and define a helper to count parameters.\n"
      ],
      "metadata": {
        "id": "o1kuKS2eOpR5"
      },
      "id": "o1kuKS2eOpR5"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Pretrained ResNet-50\n",
        "resnet = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2).to(device).eval()\n",
        "\n",
        "# ImageNet normalization for feature synthesis\n",
        "IMAGENET_MEAN = torch.tensor([0.485, 0.456, 0.406], device=device)\n",
        "IMAGENET_STD  = torch.tensor([0.229, 0.224, 0.225], device=device)\n",
        "\n",
        "def count_params(m: nn.Module):\n",
        "    return sum(p.numel() for p in m.parameters())\n",
        "\n",
        "print(resnet)\n",
        "print(f\"\\nTotal params: {count_params(resnet):,}\")\n"
      ],
      "metadata": {
        "id": "oxDTZabrOpE6",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "oxDTZabrOpE6"
    },
    {
      "cell_type": "code",
      "source": [
        "# Utilities to find layers and fetch modules by dotted path\n",
        "def get_layer_by_name(model: nn.Module, dotted: str) -> nn.Module:\n",
        "    m = model\n",
        "    for part in dotted.replace('[', '.').replace(']', '').split('.'):\n",
        "        if part.isdigit():\n",
        "            m = m[int(part)]\n",
        "        else:\n",
        "            m = getattr(m, part)\n",
        "    return m\n",
        "\n",
        "conv_layers = []\n",
        "for name, m in resnet.named_modules():\n",
        "    if isinstance(m, nn.Conv2d):\n",
        "        conv_layers.append((name, m.out_channels))\n",
        "print(f\"Found {len(conv_layers)} conv layers.\")\n",
        "for name, C in conv_layers[:10]:\n",
        "    print(f\"{name:25s} -> C={C}\")\n",
        "print(\"...\")\n",
        "print(f\"Last layer: {conv_layers[-1][0]} -> C={conv_layers[-1][1]}\")\n"
      ],
      "metadata": {
        "id": "QAkSHe-l5ES3"
      },
      "execution_count": null,
      "outputs": [],
      "id": "QAkSHe-l5ES3"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class ActivationHook:\n",
        "    def __init__(self, layer: nn.Module):\n",
        "        self.h = layer.register_forward_hook(self._hook)\n",
        "        self.act = None\n",
        "    def _hook(self, m, i, o): self.act = o\n",
        "    def close(self): self.h.remove()\n",
        "\n",
        "sample_layers = [\"conv1\", \"layer2.1.conv2\", \"layer4.2.conv3\"]\n",
        "hooks = []\n",
        "for L in sample_layers:\n",
        "    hooks.append((L, ActivationHook(get_layer_by_name(resnet, L))))\n",
        "\n",
        "with torch.no_grad():\n",
        "    dummy = torch.zeros(1,3,224,224, device=device)\n",
        "    _ = resnet(dummy)\n",
        "\n",
        "for L, hk in hooks:\n",
        "    print(f\"{L:18s} -> {tuple(hk.act.shape)}\")\n",
        "    hk.close()\n"
      ],
      "metadata": {
        "id": "RMFt80005DrN"
      },
      "execution_count": null,
      "outputs": [],
      "id": "RMFt80005DrN"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def activation_channels(model, layer_name: str, H: int = 224) -> int:\n",
        "    L = get_layer_by_name(model, layer_name)\n",
        "    hk = ActivationHook(L)\n",
        "    with torch.no_grad():\n",
        "        _ = model(torch.zeros(1,3,H,H, device=device))\n",
        "        C = hk.act.shape[1]\n",
        "    hk.close()\n",
        "    return C\n",
        "\n",
        "def evenly_spaced_channels(C: int, k: int = 5):\n",
        "    idx = np.linspace(0, C-1, num=min(k, C), dtype=int).tolist()\n",
        "    return sorted(set(int(i) for i in idx))\n",
        "\n",
        "@torch.no_grad()\n",
        "def topk_active_channels(model, layer_name: str, images: torch.Tensor, k: int = 5):\n",
        "    \"\"\"images: (B,3,H,W) already normalized to ImageNet stats.\"\"\"\n",
        "    L = get_layer_by_name(model, layer_name)\n",
        "    hk = ActivationHook(L)\n",
        "    _ = model(images.to(device))\n",
        "    # mean over (B,H,W) to score channels\n",
        "    score = hk.act.mean(dim=(0,2,3))\n",
        "    hk.close()\n",
        "    topk = torch.topk(score, k=min(k, score.numel()))[1].tolist()\n",
        "    return sorted(topk)\n"
      ],
      "metadata": {
        "id": "OD30eIRI49F0"
      },
      "execution_count": null,
      "outputs": [],
      "id": "OD30eIRI49F0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 2(a): Feature visualizations across layers\n"
      ],
      "metadata": {
        "id": "TLNVn7XWHhYv"
      },
      "id": "TLNVn7XWHhYv"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Representation Synthesis\n",
        "\n",
        "Given a (layer, channel), we synthesize an image \\(x\\) that maximizes the **mean activation** of that channel while using L1/L2 penalties:\n",
        "\n",
        "$$\n",
        "x^* \\;=\\; \\underset{x}{\\operatorname*{arg\\,max}} \\;\n",
        "\\mathbb{E}_{u,v}\\!\\left[a_{\\ell,c}(x)_{u,v}\\right]\n",
        "\\;-\\; \\lambda_2 \\,\\lVert x\\rVert_2^2\n",
        "\\;-\\; \\lambda_1 \\,\\lVert x\\rVert_1\n",
        "\\;-\\; \\lambda_{\\nabla} \\,\\lVert \\nabla x \\rVert_2^2.\n",
        "$$\n",
        "\n",
        "- $\\lVert x \\rVert_2^2$: keeps pixel energy bounded (L2 “weight decay” on the input).\n",
        "- $\\lVert x \\rVert_1$: encourages sparsity (fewer, stronger strokes).\n",
        "- $\\lVert \\nabla x \\rVert_2^2$: smoothness via L2 on image gradients.\n",
        "\n"
      ],
      "metadata": {
        "id": "JcMGwBkIPF_H"
      },
      "id": "JcMGwBkIPF_H"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def denorm(x):\n",
        "    return (x * IMAGENET_STD.view(1,3,1,1) + IMAGENET_MEAN.view(1,3,1,1)).clamp(0,1)\n",
        "\n",
        "def grad_l2_loss(x: torch.Tensor, weight: float = 1.0) -> torch.Tensor:\n",
        "    \"\"\"L2 on image gradients (finite differences)\"\"\"\n",
        "    dx = x[:,:,:,1:] - x[:,:,:,:-1]\n",
        "    dy = x[:,:,1:,:] - x[:,:,:-1,:]\n",
        "    return weight * ((dx**2).mean() + (dy**2).mean())\n",
        "\n",
        "def synthesize_channel_image_l2only(\n",
        "    model: nn.Module,\n",
        "    layer_name: str,\n",
        "    channel: int,\n",
        "    steps: int = 220, lr: float = 0.18,\n",
        "    l2_w: float = 3e-7, l1_w: float = 0.0, grad_l2_w: float = 0.0,\n",
        "    jitter: int = 8, blur_every: int = 0, blur_ksize: int = 3,\n",
        "    seed: int = 0, init_std: float = 0.05, size: int = 224\n",
        "):\n",
        "    \"\"\"\n",
        "    Gradient ascent on the input to maximize the mean activation of (layer, channel).\n",
        "    Students fill the #FIXME lines (forward → objective → backward → update).\n",
        "    \"\"\"\n",
        "    layer = get_layer_by_name(model, layer_name)\n",
        "\n",
        "    # initialize in ImageNet-normalized space (given)\n",
        "    g = torch.Generator(device=device).manual_seed(seed)\n",
        "    x = torch.randn(1,3,size,size, device=device, generator=g) * init_std\n",
        "    x = (x - x.min())/(x.max()-x.min()+1e-8)  # [0,1]\n",
        "    x = (x - IMAGENET_MEAN.view(1,3,1,1)) / IMAGENET_STD.view(1,3,1,1)\n",
        "    x.requires_grad_(True)\n",
        "\n",
        "    hk = ActivationHook(layer)\n",
        "    opt = torch.optim.Adam([x], lr=lr)\n",
        "\n",
        "    for t in range(steps):\n",
        "        opt.zero_grad()\n",
        "\n",
        "        # Random jitter (given)\n",
        "        ox = 0 if jitter==0 else torch.randint(-jitter, jitter+1, (1,), device=device).item()\n",
        "        oy = 0 if jitter==0 else torch.randint(-jitter, jitter+1, (1,), device=device).item()\n",
        "\n",
        "        # FIXME 1: Create the jittered input xj by rolling x by (ox, oy)\n",
        "        xj = #FIXME\n",
        "\n",
        "        # FIXME 2: Forward pass the jittered image through the model\n",
        "        _ = #FIXME\n",
        "\n",
        "        # FIXME 3: Read the activation tensor from the hook and isolate the target channel\n",
        "        act = #FIXME\n",
        "\n",
        "        # FIXME 4: Activation objective for gradient ASCENT: negative mean of that channel\n",
        "        loss_act = #FIXME\n",
        "\n",
        "        # Regularization terms (students wire simple L2/L1; grad-L2 optional)\n",
        "        loss_reg = 0.0\n",
        "\n",
        "        # FIXME 5: L2 on pixels (in normalized space)\n",
        "        if l2_w > 0:\n",
        "            loss_reg = #FIXME\n",
        "\n",
        "        # FIXME 6: L1 on pixels (optional; leave at 0 to disable)\n",
        "        if l1_w > 0:\n",
        "            loss_reg = #FIXME\n",
        "\n",
        "        # FIXME 7 (optional): L2 on image gradients in *image* space for smoothness\n",
        "        if grad_l2_w > 0:\n",
        "            loss_reg = #FIXME\n",
        "\n",
        "        # FIXME 8: Total loss = activation objective + regularization\n",
        "        loss = #FIXME\n",
        "\n",
        "        # FIXME 9: Backprop through x\n",
        "\n",
        "\n",
        "        # FIXME 10: Optimizer step (performs the ascent because loss_act is negated)\n",
        "\n",
        "\n",
        "        # Undo jitter\n",
        "        with torch.no_grad():\n",
        "            x.copy_(torch.roll(torch.roll(x, -ox, 3), -oy, 2))\n",
        "\n",
        "        # Optional blur every N steps\n",
        "        if blur_every and (t+1) % blur_every == 0:\n",
        "            with torch.no_grad():\n",
        "                pad = blur_ksize // 2\n",
        "                x.copy_(F.avg_pool2d(x, kernel_size=blur_ksize, stride=1, padding=pad))\n",
        "\n",
        "    hk.close()\n",
        "    return x.detach()\n"
      ],
      "metadata": {
        "id": "yqvWJQdgPDzh"
      },
      "execution_count": null,
      "outputs": [],
      "id": "yqvWJQdgPDzh"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5×5 feature panel across distant layers\n",
        "\n",
        "We visualize five channels from each of five **distant** conv layers in ResNet-50 to make the representation hierarchy obvious:\n",
        "\n",
        "Each cell is an image synthesized by our **gradient ascent on the input** to maximally activate one channel in the chosen layer.  \n",
        "Rows = layers (shallow → deep). Columns = different channels within the layer.\n"
      ],
      "metadata": {
        "id": "-jH_FbH5f4vd"
      },
      "id": "-jH_FbH5f4vd"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.utils import make_grid, save_image\n",
        "\n",
        "# five distant layers (stage ends)\n",
        "layers_5 = [\n",
        "    \"conv1\",            # very early\n",
        "    \"layer1.2.conv3\",   # end of stage 1\n",
        "    \"layer2.3.conv3\",   # end of stage 2\n",
        "    \"layer3.5.conv3\",   # end of stage 3\n",
        "    \"layer4.2.conv3\",   # end of stage 4\n",
        "]\n",
        "\n",
        "# Per-layer hyperparams (deeper → a bit more steps/smoothness)\n",
        "steps_for = {\n",
        "    \"conv1\":          160,\n",
        "    \"layer1.2.conv3\": 200,\n",
        "    \"layer2.3.conv3\": 240,\n",
        "    \"layer3.5.conv3\": 300,\n",
        "    \"layer4.2.conv3\": 340,\n",
        "}\n",
        "grad_l2_for = {\n",
        "    \"conv1\":          0.0,\n",
        "    \"layer1.2.conv3\": 1e-5,\n",
        "    \"layer2.3.conv3\": 2e-5,\n",
        "    \"layer3.5.conv3\": 3e-5,\n",
        "    \"layer4.2.conv3\": 5e-5,\n",
        "}\n",
        "\n",
        "# select channels\n",
        "picked = {}\n",
        "imgs = []\n",
        "for L in layers_5:\n",
        "    C = activation_channels(resnet, L)\n",
        "    chs = evenly_spaced_channels(C, k=5)\n",
        "    picked[L] = chs\n",
        "    print(f\"{L}: C={C}, channels={chs}\")\n",
        "    for c in chs:\n",
        "        x = synthesize_channel_image_l2only(\n",
        "            resnet, L, c,\n",
        "            steps=steps_for.get(L, 240), lr=0.18,\n",
        "            l2_w=3e-7, l1_w=0.0, grad_l2_w=grad_l2_for.get(L, 0.0),\n",
        "            jitter=8, blur_every=0\n",
        "        )\n",
        "        imgs.append(denorm(x))\n",
        "\n",
        "panel = make_grid(torch.cat(imgs, 0), nrow=5)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(12,9))\n",
        "plt.imshow(panel.cpu().permute(1,2,0))\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"ResNet-50 feature maximization — rows=layers (shallow→deep), cols=channels\", pad=12)\n",
        "\n",
        "\n",
        "H, W = panel.shape[1], panel.shape[2]\n",
        "rows_n, cols_n = 5, 5\n",
        "row_h, col_w = H // rows_n, W // cols_n\n",
        "\n",
        "# row labels (layer names)\n",
        "for r, L in enumerate(layers_5):\n",
        "    y = r*row_h + 18\n",
        "    plt.text(6, y, L, color='white', fontsize=11, weight='bold',\n",
        "             bbox=dict(facecolor='black', alpha=0.45, pad=2))\n",
        "\n",
        "# per-cell channel labels\n",
        "for r, L in enumerate(layers_5):\n",
        "    for c, ch in enumerate(picked[L]):\n",
        "        x = c*col_w + 6\n",
        "        y = r*row_h + row_h - 10\n",
        "        plt.text(x, y, f\"ch {ch}\", color='white', fontsize=9,\n",
        "                 bbox=dict(facecolor='black', alpha=0.35, pad=1))\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "BAvXg9v9f53G"
      },
      "execution_count": null,
      "outputs": [],
      "id": "BAvXg9v9f53G"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2(b) Residual Connection Anatomy\n",
        "\n",
        "We compare three taps around a *non-projection* residual block (`layer2.1`):\n",
        "1) **Origin** of the skip (the output of the previous block): `layer2.0`  \n",
        "2) **Pre-add residual** (output of the residual branch just before the sum): `layer2.1.bn3`  \n",
        "3) **Post-add (+ReLU) output** (block output after skip + residual): `layer2.1`"
      ],
      "metadata": {
        "id": "XSpKUuipntEK"
      },
      "id": "XSpKUuipntEK"
    },
    {
      "cell_type": "code",
      "source": [
        "class IOHook:\n",
        "    def __init__(self, layer, capture=\"output\"):\n",
        "        assert capture in (\"output\", \"input\")\n",
        "        self.capture = capture\n",
        "        self.h = layer.register_forward_hook(self._hook)\n",
        "        self.act = None\n",
        "    def _hook(self, m, inp, out):\n",
        "        self.act = inp[0] if self.capture == \"input\" else out\n",
        "    def close(self):\n",
        "        self.h.remove()\n",
        "\n",
        "\n",
        "def synthesize_linear_combo(\n",
        "    model,\n",
        "    taps,\n",
        "    channel,\n",
        "    weights,\n",
        "    steps=260, lr=0.18,\n",
        "    l2_w=3e-7, grad_l2_w=2e-5,\n",
        "    jitter=8, seed=0, size=224\n",
        "):\n",
        "    assert len(taps) == len(weights) and len(taps) > 0\n",
        "\n",
        "\n",
        "    layers   = [get_layer_by_name(model, name) for name, _ in taps]\n",
        "    captures = [cap for _, cap in taps]\n",
        "\n",
        "    hooks0 = [IOHook(layer, capture=cap) for layer, cap in zip(layers, captures)]\n",
        "    with torch.no_grad():\n",
        "        _ = model(torch.zeros(1,3,size,size, device=device))\n",
        "        Cs = [h.act.shape[1] for h in hooks0]\n",
        "    for h in hooks0: h.close()\n",
        "    assert len(set(Cs)) == 1, f\"Channel size mismatch across taps: {Cs}\"\n",
        "    C = Cs[0]\n",
        "    assert 0 <= channel < C\n",
        "\n",
        "\n",
        "    g = torch.Generator(device=device).manual_seed(seed)\n",
        "    x = torch.randn(1,3,size,size, device=device, generator=g)*0.05\n",
        "    x = (x - x.min())/(x.max()-x.min()+1e-8)\n",
        "    x = (x - IMAGENET_MEAN.view(1,3,1,1)) / IMAGENET_STD.view(1,3,1,1)\n",
        "    x.requires_grad_(True)\n",
        "\n",
        "    hooks = [IOHook(layer, capture=cap) for layer, cap in zip(layers, captures)]\n",
        "    opt = torch.optim.Adam([x], lr=lr)\n",
        "\n",
        "    for _ in range(steps):\n",
        "        opt.zero_grad()\n",
        "        ox = 0 if jitter==0 else torch.randint(-jitter, jitter+1, (1,), device=device).item()\n",
        "        oy = 0 if jitter==0 else torch.randint(-jitter, jitter+1, (1,), device=device).item()\n",
        "        xj = torch.roll(torch.roll(x, ox, 3), oy, 2)\n",
        "\n",
        "        model(xj)\n",
        "        combo = 0.0\n",
        "        for w, h in zip(weights, hooks):\n",
        "            combo = combo + w * h.act[:, channel].mean()\n",
        "\n",
        "        loss = -combo + l2_w*(x**2).mean()\n",
        "        if grad_l2_w > 0:\n",
        "            dx = denorm(x)[:,:,:,1:] - denorm(x)[:,:,:,:-1]\n",
        "            dy = denorm(x)[:,:,1:,:] - denorm(x)[:,:,:-1,:]\n",
        "            loss = loss + grad_l2_w*((dx**2).mean() + (dy**2).mean())\n",
        "\n",
        "        loss.backward(); opt.step()\n",
        "        with torch.no_grad():\n",
        "            x.copy_(torch.roll(torch.roll(x, -ox, 3), -oy, 2))\n",
        "\n",
        "    for h in hooks: h.close()\n",
        "    return denorm(x.detach())\n",
        "\n",
        "\n",
        "origin_tap = (\"layer2.0\",     \"output\")\n",
        "pre_tap    = (\"layer2.1.bn3\", \"output\")\n",
        "post_tap   = (\"layer2.1\",     \"output\")\n",
        "\n",
        "tmp = IOHook(get_layer_by_name(resnet, pre_tap[0]), capture=pre_tap[1])\n",
        "with torch.no_grad(): _ = resnet(torch.zeros(1,3,224,224, device=device))\n",
        "C = tmp.act.shape[1]; tmp.close()\n",
        "chs = evenly_spaced_channels(C, k=5)\n",
        "print(f\"layer2.1 identity block: C={C}, channels={chs}\")\n",
        "\n",
        "rows_imgs = []\n",
        "\n",
        "\n",
        "for c in chs:\n",
        "    rows_imgs.append(synthesize_linear_combo(resnet, [origin_tap], c, [1.0],\n",
        "                    steps=240, grad_l2_w=2e-5))\n",
        "\n",
        "for c in chs:\n",
        "    rows_imgs.append(synthesize_linear_combo(resnet, [pre_tap], c, [1.0],\n",
        "                    steps=240, grad_l2_w=2e-5))\n",
        "\n",
        "for c in chs:\n",
        "    rows_imgs.append(synthesize_linear_combo(resnet, [post_tap], c, [1.0],\n",
        "                    steps=260, grad_l2_w=2e-5))\n",
        "\n",
        "for c in chs:\n",
        "    rows_imgs.append(synthesize_linear_combo(resnet, [pre_tap, origin_tap], c, [1.0, -1.0],\n",
        "                    steps=280, grad_l2_w=3e-5))\n",
        "\n",
        "for c in chs:\n",
        "    rows_imgs.append(synthesize_linear_combo(resnet, [post_tap, pre_tap], c, [1.0, -1.0],\n",
        "                    steps=300, grad_l2_w=3e-5))\n",
        "\n",
        "for c in chs:\n",
        "    rows_imgs.append(synthesize_linear_combo(resnet, [post_tap, pre_tap, origin_tap], c, [1.0, -2.0, 1.0],\n",
        "                    steps=320, grad_l2_w=3e-5))\n",
        "\n",
        "panel = make_grid(torch.cat(rows_imgs, 0), nrow=5)\n",
        "\n",
        "plt.figure(figsize=(12,10))\n",
        "plt.imshow(panel.cpu().permute(1,2,0)); plt.axis(\"off\")\n",
        "plt.title(\"Identity block (layer2.1): origin / pre-add / post-add and their deltas\", pad=10)\n",
        "\n",
        "# Row labels\n",
        "H, W = panel.shape[1], panel.shape[2]\n",
        "row_h, col_w = H // 6, W // 5\n",
        "labels = [\n",
        "    \"Origin — layer2.0\",\n",
        "    \"Pre-add — layer2.1.bn3\",\n",
        "    \"Post-add (+ReLU) — layer2.1\",\n",
        "    \"Δ (pre − origin)\",\n",
        "    \"Δ (post − pre)\",\n",
        "    \"ΔΔ = post − 2·pre + origin\",\n",
        "]\n",
        "for r, lab in enumerate(labels):\n",
        "    y = r*row_h + 18\n",
        "    plt.text(6, y, lab, color='white', fontsize=11, weight='bold',\n",
        "             bbox=dict(facecolor='black', alpha=0.45, pad=2))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ROyvhIeVoiVY"
      },
      "execution_count": null,
      "outputs": [],
      "id": "ROyvhIeVoiVY"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2(c) Layer types at the same depth: conv vs identity block vs projection block\n",
        "\n",
        "Goal: Compare learned features **controlling for depth** (same stage). We’ll visualize five channels from:\n",
        "\n",
        "1) **Conv path only** — `layer3.1.bn3` (output of the residual branch before the skip is added)\n",
        "2) **Identity block output** — `layer3.1` (post-add + ReLU; skip is identity)\n",
        "3) **Projection block output** — `layer3.0` (post-add + ReLU; skip uses a 1×1 conv to project)\n",
        "\n",
        "All of these are in **stage 3** (same spatial size and channel width).  \n",
        "\n"
      ],
      "metadata": {
        "id": "LBDhSEexvSYt"
      },
      "id": "LBDhSEexvSYt"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.utils import make_grid, save_image\n",
        "\n",
        "\n",
        "stage = 3\n",
        "\n",
        "id_block = f\"layer{stage}.1\"   # identity block (skip is identity)\n",
        "proj_block = f\"layer{stage}.0\" # projection block (skip uses conv)\n",
        "conv_path = f\"{id_block}.bn3\"  # conv stack's final BN (pre-add)\n",
        "\n",
        "class IOHook:\n",
        "    def __init__(self, layer, capture=\"output\"):\n",
        "        assert capture in (\"output\",\"input\")\n",
        "        self.capture = capture\n",
        "        self.h = layer.register_forward_hook(self._hook)\n",
        "        self.act = None\n",
        "    def _hook(self, m, inp, out):\n",
        "        self.act = inp[0] if self.capture==\"input\" else out\n",
        "    def close(self): self.h.remove()\n",
        "\n",
        "hk = IOHook(get_layer_by_name(resnet, conv_path), capture=\"output\")\n",
        "with torch.no_grad():\n",
        "    _ = resnet(torch.zeros(1,3,224,224, device=device))\n",
        "C = hk.act.shape[1]; hk.close()\n",
        "\n",
        "chs = evenly_spaced_channels(C, k=5)\n",
        "print(f\"Stage {stage}: C={C}, channels={chs}\")\n",
        "rows = [\n",
        "    (\"Conv path only — \" + conv_path, conv_path, \"output\"),\n",
        "    (\"Identity block (post-add) — \" + id_block, id_block, \"output\"),\n",
        "    (\"Projection block (post-add) — \" + proj_block, proj_block, \"output\"),\n",
        "]\n",
        "\n",
        "# Slightly stronger smoothness for deeper stages\n",
        "grad_l2 = {2:2e-5, 3:3e-5, 4:5e-5}.get(stage, 2e-5)\n",
        "steps   = {2:240,  3:300,  4:340}.get(stage, 260)\n",
        "\n",
        "imgs = []\n",
        "for title, tap, capture in rows:\n",
        "    print(title)\n",
        "    for c in chs:\n",
        "        if capture != \"output\":\n",
        "            raise ValueError(\"In this cell we only use module outputs.\")\n",
        "        x = synthesize_channel_image_l2only(\n",
        "            resnet, tap, c,\n",
        "            steps=steps, lr=0.18,\n",
        "            l2_w=3e-7, l1_w=0.0, grad_l2_w=grad_l2,\n",
        "            jitter=8, blur_every=0,\n",
        "            seed=SEED\n",
        "        )\n",
        "        imgs.append(denorm(x))\n",
        "\n",
        "panel = make_grid(torch.cat(imgs,0), nrow=5)\n",
        "\n",
        "plt.figure(figsize=(12,7))\n",
        "plt.imshow(panel.cpu().permute(1,2,0)); plt.axis(\"off\")\n",
        "plt.title(f\"Stage {stage}: conv path vs identity block vs projection block\", pad=10)\n",
        "\n",
        "H, W = panel.shape[1], panel.shape[2]\n",
        "row_h, col_w = H // 3, W // 5\n",
        "for r, (title, _, __) in enumerate(rows):\n",
        "    y = r*row_h + 18\n",
        "    plt.text(6, y, title, color='white', fontsize=11, weight='bold',\n",
        "             bbox=dict(facecolor='black', alpha=0.45, pad=2))\n",
        "\n",
        "for r in range(3):\n",
        "    for c, ch in enumerate(chs):\n",
        "        x = c*col_w + 6\n",
        "        y = r*row_h + row_h - 10\n",
        "        plt.text(x, y, f\"ch {ch}\", color='white', fontsize=9,\n",
        "                 bbox=dict(facecolor='black', alpha=0.35, pad=1))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "QSYuAXmrvTT1"
      },
      "execution_count": null,
      "outputs": [],
      "id": "QSYuAXmrvTT1"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}